%Kompilierung mit:
%latex -interaction=nonstopmode %.tex|bibtex %|dvipdfm %.dvi|"D:/Programme/Foxit Reader/Foxit Reader.exe" %.pdf

\documentclass[a4paper, 10pt]{article}
%\usepackage[utf8]{inputenc}			
\usepackage[german]{babel}		% for german	
\usepackage{graphicx}								
\usepackage{parskip}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{empheq}
\usepackage{titlesec}	
%\usepackage{tabularx}
%\usepackage{pdfpages}
%\usepackage{hyperref,breakurl}
%\usepackage{url}
%\usepackage{psfrag}
\usepackage{epstopdf}
\usepackage{sectsty}
\allsectionsfont{\bfseries\sffamily}

\addtolength{\textwidth}{2.1cm}
\addtolength{\topmargin}{-1.4cm}
\addtolength{\oddsidemargin}{-1.1 cm}
\definecolor{leichtgrau}{gray}{0.91}
\setlength{\parindent}{0pt}

% \lstset{language = C,
	% basicstyle=\footnotesize,       
	% numbers=left,                  
	% numberstyle=\footnotesize,      
	% stepnumber=2,
	% numbersep=5pt,
	% backgroundcolor=\color{leichtgrau},
	% frame=single,
% }

% Definition von römischen Zahlen
\newcommand{\rom}[1]{$\underline{\overline{\text{#1}}}$} 
%\renewcommand{\familydefault}{\sfdefault}


\begin{document}
\section{SIMO Systems}
\subsubsection*{Remarks}
\begin{itemize}
	\item In SIMO Systems only \underline{coding} and \underline{diversity} \underline{gains} can be exploited (no multiplexing gains)
	\item To realize these gains diversity combining has to be performed
	\item Diversity combining schemes vary in complexity and performance
	\item There are \underline{many} diversity combining schemes. Here we consider:
	\begin{itemize}
		\item Maximal ratio combining (MRC)
		\item Equal gain combining (EGC)
		\item Selection combining (SC)
	\end{itemize}
	\item Diversity combining problem
	\begin{figure}[h]\centering
		\includegraphics[width=0.8\textwidth]{Multi_Channel}
	\end{figure}		
	
	\begin{itemize}
		\item how to choose combining weights $w_n$?
		\item what performance (e.g. error rate, outage probability) is achieved?
		\item what \underline{diversity} and coding/combining gain is achieved?
	\end{itemize}
\end{itemize}
\begin{minipage}[hbt]{7cm}
	\centering
	\includegraphics[width=7cm]{SIMO_BER_SNR_Kurve}
\end{minipage}
\hfill
\begin{minipage}[hbt]{5cm}
	\centering
		\begin{itemize}
			\item $G_c$ : Coding gain
			\item $G_d$ : Diversity gain
		\end{itemize}
\end{minipage}

\subsection{Preliminaries}
Consider an equivalent system:
\begin{align*}
	y &= hx +n;\\
	\mathcal{E}\{|x^2|\} &= E_s; & \mathcal{E}\{|n^2|\} &= \sigma_n^2; & \mathcal{E}\{|h|^2\} &= 1
\end{align*}
\begin{itemize}
	\item Instantaneous SNR: $\gamma_t = \frac{E_s}{\sigma_n^2}\times |h|^2$
\item Average SNR: $\bar{\gamma}_t = \mathcal{E}\{\gamma_t\} = \frac{E_s}{\sigma_n^2}$
\end{itemize}
\paragraph{Bit and Symbol Error Rate}
\begin{itemize}
	\item The Bit and Symbol Error Rate of many modulation schemes can be expressed for given $\gamma_t$ as:
\end{itemize}
\begin{align*}
	P_e(\gamma_t) = aQ\bigl\{ \sqrt{b\gamma_t}\bigr\}
\end{align*}
where:
\begin{itemize}
	\item $Q(x) = \frac{1}{\sqrt{2\pi}}\times\int_{x}^{\infty} e^{-\frac{t^2}{2}}~dt$
	\item $P_e(\gamma_t)$ may be exact result or approximation
	\item BPSK: exact with $a = 1, b = 2$
	\item M-ary QAM: tight approximation with $a = 4\bigl (1-\frac{1}{\sqrt{M}}\bigr ), b =  \frac{3}{M - 1}$
\end{itemize}
\begin{math} \bigl ({\small Einschub: Gray-Code: {BER} = \frac{1}{\log_2M} \times {SER} }\bigr ) \end{math}
\begin{itemize}
	\item Alternative representation of Q\;-\;function:
			\begin{align*} 
			Q(x) = \frac{1}{\pi}\int_{0}^{\frac{\pi}{2}} e^{-\frac{x^2}{2sin^2\theta}}~d\theta
			\end{align*}
			$\rightarrow$ Integral limits are fixed and do not depend on integration variables!
	\item Average error probability
		\begin{align*} 
		P_e = \mathcal{E}\bigl \{P_e(\gamma_t)\bigr \} = \int_{0}^{\infty}aQ\bigr (\sqrt{bx}\bigl )p_{\gamma_t}(x)~\mathrm{d}x
		\end{align*}
		\begin{itemize}
			\item Integral may be difficult to solve analytically
			\item Integral has infinite support $\rightarrow$ numerical evaluation difficult
		\end{itemize}
	\item Using alternative representation of Q-function we get:
		\begin{align*}
			P_e &= \int_{0}^{\infty}\frac{a}{\pi}\int_{0}^{\frac{\pi}{2}}e^{-\frac{bx}{2sin^2\theta}}p_{\gamma_t}(x)~d\theta ~dx\\
			&= \frac{a}{\pi}\int_{0}^{\frac{\pi}{2}}\int_{0}^{\infty}p_{\gamma_t}(x)e^{-\frac{b}{2sin^2\theta}}~dx~d\theta &= \frac{a}{\pi}\int_{0}^{\frac{\pi}{2}}M_{\gamma_t}\bigl ( \frac{b}{2sin^2\theta} \bigr )~d\theta
		\end{align*}
where:
		\begin{itemize}
				\item $M_{\gamma_t}(s) = \int_{0}^{\infty}p_{\gamma_t}(x)e^{-sx}~dx$ is the Laplace transform of $p_{\gamma_t}$	
				\item $M_{\gamma_t}(-s)$ is the so called Moment Generation Function (MGF) of $p_{\gamma_t}$
				\item Here, we will also refer to $M_{\gamma_t}(s)$ as MGF
				\item $M_{\gamma_t}(s)$ is sometimes easier to obtain than $p_{\gamma_t}$
				\item The above integral can be easily evaluated numerically because of the finite integral limits
			\end{itemize}
\end{itemize}
\paragraph{Outage probability}
\begin{itemize}
	\item The outage probability is the probability that the channel cannot support a certain rate, R, i.e. (where \begin{math} \gamma_T \end{math} is the threshold SNR):
		\begin{align*}
			C = \log_2(1+\gamma_t) < R \quad \leftrightarrow \quad \gamma_t < 2^R - 1 \triangleq \gamma_T
		\end{align*}\\
		Thus, the outage probability is given by:
		\begin{align*}
			P_{out} &= P_0 {\gamma_t <\gamma-T}  \;= \int_{0}^{\gamma_T}p_{\gamma_t}(x)~dx
		\end{align*}
\item Using the inverse Laplace Transform\\
\begin{minipage}[hbt]{7cm}
	\centering
		\begin{align*}
			p_{\gamma  _t}(x) = \frac{1}{2\pi j}\int_{c-j\omega}^{c+j\omega}M_{\gamma _t}(s)e^{sx}~dx
		\end{align*}
	where \begin{math} c > 0\end{math} is a small constant that lies in the region of convergence of the integral, we obtain:
\end{minipage}
\hfill
\begin{minipage}[hbt]{5cm}
	\centering
	\includegraphics[width=2cm]{SIMO_Konstante_c}
\end{minipage}

\begin{itemize}
	\item 1.
			\begin{align*}
				P_{out} = \frac{1}{2\pi j}\int_{c-j\omega}^{c+j\omega}M_{\gamma _t}(s)\int_{0}^{\gamma _T}e^{sx}~dx~ds = \frac{1}{2\pi j}\int_{c-j\omega}^{c+j\omega}M_{\gamma _t}(s)e^{\gamma _Ts}~\frac{ds}{s}
			\end{align*}
			\begin{math}\bigl (\end{math}lower integral limit is 0 since \begin{math}p_{\gamma _t}(0) = 0 \bigr )\end{math}
	\item and 2.:
		\begin{align*}
			p_{\gamma _t} (x) &= \int_{0}^{x} p_{\gamma _t}(t) ~dt = 0\\		
		\text{for } x &= 0 \text{ note: } p_{\gamma _t}(x) \xleftrightarrow [transform]{Laplace} \frac{1}{s}M_{\gamma _t}(s)
		\end{align*}
	\end{itemize}
\end{itemize}
\paragraph{General combining scheme}
\begin{align*}
	y &= \Bigl (\sum_{n = 1}^{N_R}h_nw_n\Bigr )x + \sum_{n = 1}^{N_R}w_nn_n \\
	\gamma _t &= \frac{\epsilon _s \Bigl | \sum_{n = 1}^{N_R}h_nw_n\Bigr |^2 }{\sigma _n^2 \sum_{N = 1}^{N_R}|w_n|^2}
\end{align*}
where \begin{math} w_n\end{math} depends on the particular combining scheme.
\subsection{MRC (Maximum Ratio Combining)}
\begin{itemize}
	\item what weight \begin{math}w_n\end{math} maximize \begin{math}\gamma _t\end{math}?
	\begin{itemize}
		\item Cauchy-Schwarz inequality
		\begin{align*}
			\Bigl | \sum_{n = 1}^{N_R}h_nw_n\Bigr |^2 \leq \sum_{n = 1}^{N_R}|h_n|^2 \cdot \sum_{n = 1}^{N_R}|w_n|^2
		\end{align*}
	where equality holds if and only if \begin{math}w_n = c\cdot h_n^*\end{math} for some non-zero constant \begin{math}c\end{math}.
		\item for \begin{math}w_n = h_n^*\end{math}, we obtain
		\begin{align*}
			\gamma _t = \frac{\epsilon _s}{\sigma _n^2}\cdot \frac{\Bigl ( \sum_{n = 1}^{N_R}|h_n|^2\Bigr ) ^2}{\sum_{n = 1}^{N_R}|h_n|^2} = \frac{\epsilon _s}{\sigma _n^2}\sum_{n = 1}^{N_R}|h_n|^2
		\end{align*}
		\item \begin{math}w_n = h_n^* \forall n\end{math} are the MRC combining weights.	
	\end{itemize}
	\item For performance analysis we assume \underline{independent identically distributed (IID)} Rayleigh fading
		\begin{align*}
			\rightarrow \mathcal{E}\{|h_n|^2\} &= 1; \quad \bar{\gamma} = \frac{\epsilon _s}{\sigma	_n^2}; \quad \gamma _n = \frac{\epsilon _s}{\sigma _n^2}|h_n|^2\\
			p_{\gamma}(x) &= \frac{1}{\bar{\gamma}}e^{-\frac{x}{\bar{\gamma}}}; \quad x\geq 0\\
			M_{\gamma}(s) &= \frac{1}{1+s\bar{\gamma}}
		\end{align*}		
	\item Error rate
			\begin{align*}
				\gamma _t = \sum_{n = 1}^{N_R}\gamma _n
			\end{align*}
			\begin{math}\rightarrow \end{math} sum of IID random variables (r.v.s.)
			\begin{align*}
				M_{\gamma _t}(s) = \Bigl (M_\gamma (s)\Bigr )^{N_R} = \frac{1}{(1 + s\bar{\gamma})^{N_R}} = \frac{1}{\bar{\gamma}^{N_R}}\cdot \frac{1}{(s + \frac{1}{\bar{\gamma}})^{N_R}}
			\end{align*}
			inverse Laplace-transform (from tables)
			\begin{align*}
				p_{\gamma _t}(x) = \frac{1}{\bar{\gamma}^{N_R}}\cdot \frac{x^{N_R-1}}{(N_R - 1)!}e^{-\frac{x}{\bar{\gamma}}};\quad x\geq 0
			\end{align*}
	\item Direct approach 
		\begin{align*}
			p_e &= \int_{0}^{\infty}a\cdot Q\bigl (\sqrt{ax} \bigr )p_{\gamma _t}(x)~dx = a\Bigl (\frac{1 - \mu}{2}\Bigr )^{N_R} \cdot \sum_{n = 0}^{N_R - 1}\begin{pmatrix} N_R - 1 + n \\ n\end{pmatrix}\Bigl (\frac{1 + \mu}{2}\Bigr )^n \\ \text{where}\; \mu &= \sqrt{\frac{b\bar{\gamma}}{2 + b\bar{\gamma}}}
		\end{align*}
		\item MGF approach
			\begin{align*}
				p_e &= \frac{a}{\pi}\int_{0}^{\frac{\pi}{2}}M_{\gamma _t}\Bigl ( \frac{b}{2\sin ^2\theta}\Bigr )~d\theta \\
				&= \frac{a}{\pi}\int_{0}^{\frac{\pi}{2}}\frac{1}{\bar{\gamma}^{N_R}\bigl (\frac{b}{\sin ^2\theta} + \frac{1}{\bar{\gamma}}\bigr )^{N_R}}~d\theta \quad \text{(numerisch berechnen!)}
			\end{align*}
			\item high SNR: \quad \begin{math}\bar{\gamma}\rightarrow \infty \Longleftrightarrow \frac{1}{\bar{\gamma}}\rightarrow 0 \end{math}
	\begin{align*}
				p_e &= \frac{a}{\pi}\cdot\frac{1}{\bar{\gamma}^{N_R}}\cdot \Bigl (\frac{2}{b}\Bigr )^{N_R}\int_{0}^{\frac{\pi}{2}}\sin ^{2N_R}\theta ~d\theta \\
				 (\text{from MGF approach: }  &\int_{0}^{\frac{\pi}{2}}\sin ^{2N_R}\theta ~d\theta = \frac{\pi}{2^{N_R + 1}}\cdot \begin{pmatrix} 2N_R \\ N_R) \end{pmatrix}\\ &= \frac{a}{2^{N_R+1}\cdot b^{N_R}}\begin{pmatrix}2N_R & N_R\end{pmatrix}\frac{1}{\bar{\gamma}^{N_R}}\quad \text{as } \bar{\gamma} \rightarrow \infty \\ &\stackrel{!}{=} \Bigl (\frac{1}{G_c\bar{\gamma}}\Bigr )\\
				\text{where: Diversity gain: } & G_d = N_R\\	
				\text{Combining/Coding gain: } & G_c = 2b\Bigl (\frac{a}{2}\begin{pmatrix}2N_R \\ N_R\end{pmatrix}\Bigr )^{-\frac{1}{N_R}}	
	\end{align*}	
	\begin{figure}
		\includegraphics[width = 0.7\textwidth]{SIMO_BER_gamma_Kurve}
	\end{figure}
	\item MRC exploits the maximal possible diversity
	\item Diversity gain is not affected by correlation as the branches are not \underline{fully} correlated
	\item Diversity gain depends on fading distribution 
\end{itemize}
\paragraph*{Outage probability}
\begin{align*}
	P_{out} &= \int_{0}^{\gamma _T}p_{\gamma _t}(x)~dx = \frac{1}{\bar{\gamma}^{N_R}}\int_{0}^{\gamma _T}\frac{x^{N_R-1}}{(N_R - 1)!}e^{-\frac{x}{\bar{\gamma}}}~dx \\ &= 1- e^{-\frac{\gamma _T}{\bar{\gamma}}}\cdot \sum_{n = 1}^{N_R}\frac{\bigl (\frac{\gamma _T}{\bar{\gamma}}\bigr )^n}{(n - 1)!}
\end{align*}
\begin{itemize}
	\item Approximation (Taylor series): $\bar{\gamma}\rightarrow \infty : -e^{-\frac{x}{\bar{\gamma}}} = 1 - \frac{x}{\bar{\gamma}} + O(\frac{1}{\bar{\gamma}})$\; where a function $f(x) \text{ is } O(x) \text{ if } \lim\limits_{x\to\infty}\frac{f(x)}{x} = 0$.
\begin{align*}
	\Rightarrow P_{out}=\frac{1}{\gamma^{N_R}}\int\limits_0^{\gamma_T}\frac{x^{N_R-1}}{(N_R-1)!}\left(1-\frac{x}{\bar{\gamma}}+O\left(\frac{1}{\bar{\gamma}}\right)\right)
\end{align*}
	\item Diversity and coding gain can also be defined for $P_{out}$
\end{itemize}

\subsection{EGC (Equal Gain Combining)}

\paragraph*{Combining Weights}
\begin{itemize}
	\item For MRC, both, the amplitudes and phases of the channel gains $h_n=|h_n|e^{j\varphi_n}$ have to be known (or estimated in practice)
	\item In EGC it is assumed that only the phases are known and weights $w_n=e^{-j\varphi_n}$ are used.
\begin{align*}
	\Rightarrow \gamma_t &=\dfrac{E_s}{\sigma_n^2}\dfrac{\left|\sum\limits_{n=1}^{N_R}|h_n|e^{j\varphi_n}e^{-j\varphi_n}\right|^2}{\sum\limits^{N_R}_{n=1}\left|e^{-j\varphi_n}\right|^2}
	=\frac{E_s}{\sigma_n^2}\frac{1}{N_R}\left(\sum\limits^{N_R}_{n=1}|h_n|\right)^2\\
	&=\frac{1}{N_R}\left(\sum\limits_{n=1}^{N_R}\sqrt{\gamma_n}\right)^2;\text{  with  }\gamma_n=\frac{E_s}{\sigma_n^2}|h_n|^2
\end{align*}
\end{itemize}
\paragraph*{Performance Analysis}
\begin{itemize}
	\item IID case \\
	$\Rightarrow$ $\sqrt{\gamma_n}$ is Rayleigh distributed\\
	$\Rightarrow$ Exact analysis is much more difficult than for MRC $\Rightarrow$ see book by Simon\;\&\;Alouini p.341
	\item Approximate result
\begin{align*}
	P_e=\frac{a}{2}\left[1-\sqrt{\frac{2b\bar{\gamma}}{5+2b\bar{\gamma}}}\sum\limits_{n=0}^{N_R-1}\frac{\left(\! \begin{array}{c} 2n \\ n \end{array} \!\right) }{4^n(1+\frac{2}{5}b\bar{\gamma})^n}\right]
\end{align*}
	\item high SNR\\
	$\Rightarrow$ use high SNR analysis of Wang\;\&\;Giannakis, 2003\\
	$\Rightarrow$ at high SNR, only pdf of $\gamma_n$ around $0$ is relevant for performance
\begin{align*}
	\Rightarrow \overset{\text{Rayleigh}}{p_\gamma(x)} = \frac{1}{\bar{\gamma}}e^{-\frac{x}{\bar{\gamma}}}\overset{\text{Taylor Serie}}{=}\frac{1}{\bar{\gamma}}+O\left(\frac{1}{\bar{\gamma}}\right)\text{ as } x \to 0
\end{align*}
	\item need pdf $\gamma _t$: ($\gamma _n$ bekannt, $\rightarrow$ ges.: Wurzel, etc.)\\ (cumulative distribution function of $\sqrt{\gamma}\;(\overset{\text{i.i.d}}{=}\sqrt{\gamma_n}) $ (cdf))
	\begin{align*}
	% 1. Formel
		P_{\sqrt{\gamma}}(x) &= \text{Pr}\bigl\{\sqrt{\gamma}\leq x \bigr\} = \text{Pr}\bigl\{\gamma\leq x^2 \bigr\} = P_{\gamma}(x^2) = \text{cdf of}\;\gamma\\
	% 2. Formel
		\rightarrow p_{\sqrt{\gamma}}(x) &= \frac{d}{dx}P_{\sqrt{\gamma}}(x) = 2x\cdot p_{\gamma}(x^2) = \frac{2x}{\bar{\gamma}} + O\bigl(\frac{1}{\bar{\gamma}}\bigr)\\
	\end{align*}
	\item Laplace Transformation to MGF
	\begin{align*}
	% 3. Formel
		\rightarrow M_{\sqrt{\gamma}}(s) &= \mathcal{L}\bigl\{p_{\sqrt{\gamma}}(x)\bigr\} = \frac{2}{\bar{\gamma}}\cdot \frac{1}{s^2} + O\bigl(\frac{1}{\bar{\gamma}}\bigr)\\
	% 4. Formel
		\sqrt{\gamma _t} &= \sum_{n = 1}^{N_R}\frac{\sqrt{\gamma _n}}{N_R}\\
	% 5. Formel
		 M_{\sqrt{\gamma _t}}(s) &= \mathcal{E}\Bigl\{\mathrm{exp}({-s\sqrt{\gamma _t}})\Bigr\} = \mathcal{E}\Bigl\{\mathrm{exp}({-\frac{s}{\sqrt{N_R}}\cdot \sum_{n = 1}^{N_R}\sqrt{\gamma _n}})\Bigr\} = \Bigl(\mathcal{E}\Bigl\{\mathrm{exp}(-\frac{s}{\sqrt{N_R}}\cdot \sqrt{\gamma _n}\Bigr\}\Bigr)^{N_R}\\
	% 6. Formel
		 &= \Bigl( M_{\sqrt{\gamma}}\bigl(\frac{s}{\sqrt{N_R}}\bigr) \Bigr)^{N_R} = \Bigl(\frac{2}{\bar{\gamma}}\cdot \frac{N_R}{s^2}\Bigr)^{N_R} + O\Bigl(\frac{1}{\bar{\gamma}^{N_R}}\Bigr)\\
	\end{align*}
	\item inverse Laplace Transform
	\begin{align*}
	% 7. Formel
		p_{\sqrt{\gamma _t}}(x) &= \mathcal{L} ^{-1}\Bigl\{M_{\sqrt{\gamma _t}}(s)\Bigr\} = \Bigl(\frac{2N_R}{\bar{\gamma}}\Bigr)^{N_R}\cdot \frac{x^{2N_R-1}}{(2N_R-1)!} + O\Bigl(	\frac{1}{\bar{\gamma}^{N_R}}\Bigr)\\
	% 8. Formel
		P_{\gamma _t}(x) &= \text{Pr}\bigl\{\gamma _t\leq x	\bigr\} =  \text{Pr}\bigl\{\sqrt{\gamma _t}\leq \sqrt{x}\bigr\} = P_{\sqrt\gamma _t}(\sqrt{x}) \rightarrow \text{cdf of } \sqrt{\gamma _t}\\
	% 9. Formel
		p_{\gamma _t}(x) &= \frac{d}{dx}P_{\gamma _t}(x) = \frac{1}{2\sqrt{x}}\cdot p_{\gamma _t}(\sqrt{x}) = \frac{1}{2}\Bigl(\frac{2N_R}{\bar{\gamma}} \Bigr)^{N_R}\cdot \frac{x^{N_R-1}}{(2N_R-1)!} + O\bigl(\bar{\gamma}^{-N_R}\bigr)\\
	% 10. Formel
		\rightarrow M_{\gamma _t}(s) &= \mathcal{L}\bigl\{p_{\gamma _t}(x)\bigr\} = \frac{1}{2}\Bigl( \frac{2N_R}{\bar{\gamma}}\Bigr)^{N_R}\cdot \frac{(N_R - 1)!}{(2N_R -1)!~b^{N_R}} + O\bigl(\bar{\gamma}^{-N_R}\bigr)\\
	% 11. Formel
	\end{align*}
	\item Error Probability:
\begin{align*}
        P_e&=\frac{a}{\pi}\int\limits_0^{\frac{\pi}{2}}M_{\gamma_t}\left(\frac{b}{2\sin^2(\theta)}\right)\mathrm{d}\theta\\
        &=\frac{a}{\pi}\frac{1}{2}\left(\frac{2N_R}{\bar{\gamma}}\right)^{N_R}\frac{(N_R-1)!}{(2N_R-1)!}
        \frac{2^{N_R}}{b^{N_R}}
        \underbrace{\int\limits_0^{\frac{\pi}{2}}\sin^{2N_R}(\theta)\mathrm{d}\theta}_
        {\frac{\pi}{2^{2N_R+1}}\binom{2N_R}{N_R}=\frac{\pi(2N_R)!}{2^{2N_R+1}(N_R!)^2}}
        +O\left(\frac{1}{\bar{\gamma}^{N_R}}\right)\\
        &= \frac{aN_R^{N_R}}{2b^{N_R}N_R!}\frac{1}{\bar{\gamma}^{N_R}}+O\left(\frac{1}{\bar{\gamma}^{N_R}}\right)
        \overset{!}{=}\left(\frac{1}{G_c}\right)^{G_d}
\end{align*}

\begin{itemize}
		\item[] $\Longrightarrow \text{Diversity gain: } G_d = N_R$
		\item[] $\Longrightarrow \text{Combining gain: } G_c = \frac{b}{N_R}\Bigl( \frac{2N_R!}{a}\Bigr)^{\frac{1}{N_R}}$
		\item[] vergleiche auch Blatt mit Kurven \rom{III} und \rom{IV}
	\end{itemize}
\end{itemize}
A similar asymptotic analysis can be conducted for the outage probability.
\subsection{SC (Selection Combining)}
\paragraph*{Combining weights}
	\begin{itemize}
		\item only the strongest branch is chosen
		\item strongest branch: $\hat{n} = \underset{n}{\text{argmax}} \gamma _n \longrightarrow \gamma _t = \gamma _{\hat{n}}$
		\item only on RF receiver chain required $\rightarrow$\; saves hardware complexity 
	\end{itemize}
\paragraph*{Performance analysis}
	\begin{itemize}
		\item cdf of: $\gamma _t$
			\begin{align*}
				P_{\gamma _t}(x) &= \text{Pr}\bigl\{\gamma _{\hat{n}} \leq x\bigr\} = \text{Pr}\bigl\{\gamma _1 \leq x \cap \gamma _2 \leq x \cap \dots \gamma _{N_R} \leq x\bigr\}\\
				&\overset{(IID)}{=} \Bigl(\text{Pr}\bigl\{\gamma _n \leq x\bigr\}\Bigr)^{N_R} = \Bigl( P_{\gamma}(x)\Bigr)^{N_R}
			\end{align*}
		\item pdf:
			\begin{align*}
				p_{\gamma _t}(x) &= \frac{d}{dx}P_{\gamma _t}(x) = N_R\bigl(P_{\gamma}(x)\bigr)^{N_R-1}\cdot p_{\gamma}(x)\\
				\text{where: }\qquad p_{\gamma _t}(x) &= \frac{1}{\bar{\gamma}}e^{-\frac{x}{\bar{\gamma}}};\quad x\geq 0\\
				P_{\gamma}(x) &= \int_{0}^{x}p_{\gamma}(x)~dx = 1 - e^{-\frac{x}{\bar{\gamma}}};\quad x\geq 0\\
				\rightarrow p_{\gamma _t}(x) &= \frac{N_R}{\bar{\gamma}}\bigl( 1 - e^{-\frac{x}{\bar{\gamma}}}\bigr)^{N_R-1}e^{-\frac{x}{\bar{\gamma}}};\quad x\geq 0
			\end{align*}
	\end{itemize}
\paragraph*{Error probability}
	\begin{itemize}
		\item direct approach $\rightarrow$ closed-form solution possible
		\item MGF approach
		\begin{itemize}
			\item Binomial expansion\\
			\begin{align*}
				p_{\gamma _t}(x) &= \frac{N_R}{\bar{\gamma}}e^{-\frac{x}{\bar{\gamma}}}\sum_{n = 0}^{N_R - 1}\begin{pmatrix} N_R - 1 \\ n\end{pmatrix} 1^{N_R - 1 - n}\Bigl( -e^{-\frac{x}{\bar{\gamma}}}\Bigr)^n \\
				&= \frac{N_R}{\bar{\gamma}}\sum_{n = 0}^{N_R - 1}\begin{pmatrix}N_R - 1 \\ n\end{pmatrix}\cdot (-1)^{n}e^{-\frac{x(n + 1)}{\bar{\gamma}}};\quad	x \geq 0
			\end{align*}
			\item MGF\\
			\begin{align*}
				M_{\gamma_t}(s) = \frac{N_R}{\bar{\gamma}}\sum_{n = 0}^{N_R - 1}\begin{pmatrix}N_R - 1\\n\end{pmatrix}(-1)^{n}\frac{1}{s + \frac{n+1}{\bar{\gamma}}}
			\end{align*}
			\item 
			\begin{align*}
				P_e = \frac{a}{\pi}\int_{0}^{\frac{\pi}{2}}M_{\gamma _t}\Bigl(\frac{b}{2\sin^2\theta}\Bigr)~d\theta = \frac{aN_R}{\pi\bar{\gamma}}\sum_{n = 0}^{N_R - 1}\begin{pmatrix}N_R - 1\\ n\end{pmatrix} (-1)^{n}\int_{0}^{\frac{\pi}{2}}\frac{\mathrm{d}\theta}{\frac{b}{2\sin^2\theta} + \frac{n + 1}{\bar{\gamma}}}\\ \rightarrow\text{can be evaluated numerically}				
			\end{align*}
		\item high SNR approach $\Rightarrow \; \bar{\gamma}\rightarrow\infty$
			\begin{align*}
			p_{\gamma_t}&=\frac{N_R}{\bar{\gamma}}
			\left[1-\mathrm{exp}\left(-\frac{x}{\bar{\gamma}}\right)\right]^{N_R-1}\mathrm{exp}\left(-\frac{x}{\bar{\gamma}}\right)\\
			&\overset{\bar{\gamma} \rightarrow \infty}{=} \frac{N_R}{\bar{\gamma}}
			\left[1-\left(1-\frac{x}{\bar{\gamma}}+O\left(\bar{\gamma}^{-1}\right)\right)\right]^{N_R-1}
			\left(1-\frac{x}{\bar{\gamma}}+O\left(\bar{\gamma}^{-1}\right)\right)i\\
			&=\frac{N_R}{\bar{\gamma}^{N_R}}x^{N_R-1}+o\left(\bar{\gamma}^{-N_R}\right)
			\end{align*}
		\item MGF:
			\begin{align*}
			M_{\gamma_t}(s)&=\frac{N_R}{\bar{\gamma}^{N_R}}\frac{(N_R-1)!}{s^{N_R}}+O\left(\bar{\gamma}^{-N_R}\right)\\
			\Bigl[\rightarrow P_e&=\frac{a}{\pi}\int\limits^{\frac{\pi}{2}}_0 M_{\gamma_t}\left(\frac{b}{2\sin^2(\theta)}\right)\mathrm{d}\theta\Bigr]\\
			&=\frac{a(2N_R)!}{b^{N_R}2^{N_R+1}N_R!}\frac{1}{\bar{\gamma}^{N_R}}+O(\bar{\gamma}^{-N_R})
			\end{align*}
		\begin{itemize}
			\item[] $\Longrightarrow \text{Diversity gain: } G_d = N_R$
			\item[] $\Longrightarrow \text{Combining gain: } G_c = 2b\left(\frac{2N_R!}{a(2N_R)!}\right)^{\frac{1}{N_R}}$
			%\item[] vergleiche auch Blatt mit Kurven \rom{III} und \rom{IV}
		\end{itemize}
		\item Outage Probability
		\begin{align*}
			P_{out}&=\mathrm{Pr}\{\gamma_{\hat{n}} \leq \gamma_T \}=P_{\gamma_{\hat{n}}}(\gamma_T)=\left[1-\mathrm{exp}\left(-\frac{\gamma_T}{\bar{\gamma}}\right)\right]^{N_R}\\
			\text{high SNR: } P_{out}&=\left(\frac{\gamma_T}{\bar{\gamma}}\right)^{N_R}+O\left(\bar{\gamma}^{-N_R}\right)
		\end{align*}
		\end{itemize}
	\end{itemize}
\subsection{Comparison}
	\begin{itemize}
		\item Diversity Gain:\\
			MRC, EGC and SC all achieve the maximum possible diversity gain of $G_d=N_R$
		\item Combining Gain:\\
			The combining gains of MRC, EGC and SC are different
			\begin{itemize}
			\item MRC/EGC:
			\begin{align*}
			\frac{G_C^{EGC}}{G_C^{MRC}}=\frac{\frac{1}{2b}\left(\frac{a}{2}\binom{2N_R}{N_R}\right)^{\frac{1}{N_R}}}{\frac{N_R}{b}\left(\frac{a}{2}\frac{1}{N_R!}\right)^{\frac{1}{N_R}}}
			=\frac{[(2N_R)!]^{\frac{1}{N_R}}}{2N_R(N_R)^{\frac{1}{N_R}}}\leq 1\\
			\end{align*}
			(independent of a or b which are modulation parameters, only depends on number of antennas)
			\begin{align*}
				N_R \gg 1: \qquad N_R!\approx \sqrt{2\pi}e^{-N_R}N_R^{N_R+\frac{1}{2}}\qquad(Stirling)
			\end{align*}
			\begin{align*}
				\left.\frac{G_C^{EGC}}{G_C^{MRC}}\right|_{N_R\gg1}
				=\frac{\left(\sqrt{2\pi}e^{-2N_R}(2N_R)^{2N_R+\frac{1}{2}}\right)^{\frac{1}{N_R}}}{2N_R\left(\sqrt{2\pi}e^{-N_R}N_R^{N_R+\frac{1}{2}}\right)^{\frac{1}{N_R}}}
				=\frac{2\cdot2^{\frac{1}{2N_R}}}{2}\overset{N_R\rightarrow\infty}{\rightarrow}\frac{2}{e}\equiv -1.3\mathrm{dB}
			\end{align*}
			\item MRC/SC:
			\begin{align*}
				\frac{G_C^{SC}}{G_C^{MRC}}
				&=\frac{2b\left(\frac{a}{2}\binom{2N_R}{N_R}\right)^{\frac{1}{N_R}}}{2b\left(\frac{a}{2}\frac{(2N_R)!}{N_R!}\right)^{\frac{1}{N_R}}}
				=\frac{1}{(N_R!)^{\frac{1}{N_R}}} \leq 1\\
				\left.\frac{G_C^{SC}}{G_C^{MRC}}\right|_{N_R\gg1}&=\frac{1}{\sqrt{2\pi}^{\frac{1}{N_R}}e^{-1}N_R^{1+\frac{1}{2N_R}}}\overset{\rightarrow}{N_R\rightarrow\infty}\frac{e}{N_R}
			\end{align*}
			$\rightarrow$ loss increases with $N_R$
			\end{itemize}
	\end{itemize}
	\newpage
\section{MISO Systems}
\subsubsection*{Remarks}
	\begin{itemize}
		\item Similar to SIMO systems, in MISO systems only coding and diversity gains can be obtained.
		\item To realize these gains, a careful transmitter design is necessary
		\item System design depends on whether or not channel state information (\textbf{CSI}) is available at transmitter
	\end{itemize}
\subsection{Naive Approach}
\begin{itemize}	
	\item Assume we simply send the same signal over all $N_T$ transmit antennas
\end{itemize}
\input{MISO_NAIVE.pstex_t}
\begin{itemize}
	\item Transmit power: $\mathcal{E}\left\{\left|\frac{1}{\sqrt{N_T}}x\right|^2+,\dots,\left|\frac{1}{\sqrt{N_T}}x\right|^2\right\}=\mathcal{E}\left\{N_T\frac{1}{N_T}|x|^2\right\}=E_s$
	\item Received signal: $y=\frac{1}{\sqrt{N_T}}\sum\limits_{n=1}^{N_T}h_n\cdot x+n$
	\item Rayleigh fading: $h_n$ are zero mean complex gaussian random variables\\
	$\rightarrow$ $h$ is also zero mean complex gaussian
	\item i.i.d.:
	\begin{itemize}
		\item $\mathcal{E}\{|h_n|^2\}=1\;\forall n$
		\item $\mathcal{E}\{|h|^2\}=\frac{1}{N_T}\mathcal{E}\left\{\left|\sum\limits_{n=1}^{N_T}h_n\right|^2\right\}=\frac{1}{N_T}\mathcal{E}\left\{\sum\limits^{N_T}_{n=1}|h_n|^2\right\}=1$
		\item statistical properties of h are independent of $N_T$
		\item the multiple transmit antennas have no benefit at all
		\item \underline{more sophisticated transmitter designs necessary}
	\end{itemize}
\end{itemize}
\subsection{Full CSI Available at the Transmitter}
\begin{itemize}
	\item $h_n, n \in \{1,\dots,N_T\}$ is known at the transmitter
	\item Perform ``precoding'' (beamforming) with coefficients $w_n$
\end{itemize}
\input{MISO_CSI.pstex_t}
\begin{itemize}
	\item Transmit Power: Two constraints maybe considered
	\begin{itemize}
		\item Average transmit power constraint
		\begin{align*}
		P_{av}=\mathcal{E}\left\{\sum\limits^{N_T}_{n=1}|w_n^*x|^2\right\}=\sum\limits_{n=1}^{N_T}|w_n|^2\underbrace{\mathcal{E}\{|x|^2\}}_{E_s}=\mathcal{E}_s \Rightarrow \sum\limits^{N_T}_{n=1}|w_n|^2=1
		\end{align*}
		\item Power constraint for each transmit antenna
		\begin{align*}
		\rightarrow |w_n|=\frac{1}{\sqrt{N_T}} \qquad \rightarrow P_{av}=E_s
		\end{align*}
	\end{itemize}
	\item Recveived signal: $y=\underbrace{\sum\limits^{N_T}_{n=1}w^*_nh_n}_{h}x+n$ (equivalent SISO channel)
\end{itemize}
\subsubsection*{Maximum Ratio Transmission (MRT)}
\begin{itemize}
	\item we have only the average power constraint: $ \sum\limits_{n = 1}^{N_T} |w_n|^2 = 1 $
	\item SNR:  \scalebox{1.3}[1.3]{$\gamma	 _t = \frac{E_s|h|^2}{\sigma _n^2} = \frac{\mathcal{E}_s\left|\sum\limits_{n = 1}^{N_T}w_n^*\cdot h_n \right|^2}{\sigma _n^2} $} 
	\item Maximize SNR under constraint $ \sum\limits _{n = 1}^{N_T}|w_n|^2 = 1 $
	\item constraint optimization problem $\rightarrow $ Lagrange method
		\begin{align*}
			L = \frac{E_s}{\sigma _n^2}\left| \sum_{n = 1}^{N_T}w_n^*\cdot h_n \right |^2 + \lambda\left ( \sum_{n = 1}^{N_T}|w_n|^2 - 1\right ); \quad \text{where: } \lambda = \text{Lagrange Multiplier}
		\end{align*}
		$\Rightarrow$  Wirtinger Kalk\"ul: treat  $z$  and  $z^*$  as independent variables for differentiation:
		\begin{align*}
			\frac{\partial z^*}{\partial z} &= 0;\quad  \frac{\partial |z|^2}{\partial z} = \frac{\partial z\cdot z^*}{\partial z} = z^*\\
			\frac{\partial x^2}{\partial x} &= 2x; \quad \frac{\partial (z^*)^2}{\partial z^*} = 2\cdot z^*;  \frac{\partial |z|^2}{\partial z} = z^*
		\end{align*}
		\begin{align*}
			\frac{\partial L}{\partial w_m^*} = \frac{\epsilon _s}{\sigma _n^2}\Bigl ( \sum_{n = 1}^{N_T}w_n^*\cdot h_n\Bigr )^*h_m + \lambda w_m
		\end{align*}
		\begin{itemize}
			\item[$\rightarrow$] \scalebox{1.3}[1.3]{$   w_m =\underset{\text{const., independent of } m:=c}{\frac{\epsilon _s}{\sigma _n^2 \cdot \lambda}\Bigl ( \sum\limits_{n = 1}^{N_T}w_n^*h_n \Bigr )^*}h_m $}
			\item[$\rightarrow$] \scalebox{1.3}[1.3]{$  w_m = c\cdot h_m$}
			\item[$\rightarrow$] \scalebox{1.3}[1.3]{$ \sum\limits_{n = 1}^{N_T} |w_n|^2 = 1 \rightarrow c^2 = \frac{1}{\sum\limits_{n = 1}^{N_T}|h_n|^2}  $}
			\item[$\rightarrow$] \scalebox{1.3}[1.3]{$  w_n = \frac{h_n}{\sqrt{\sum\limits_{n = 1}^{N_T}|h_n|^2}} \equiv $} MRT gains 
		\end{itemize}
		\item[$\rightarrow$] SNR \scalebox{1.3}[1.3]{$ = \frac{E_s}{\sigma _n^2}\Bigl | \sum\limits_{n = 1}^{N_T}\frac{|h_n|^2}{\sqrt{\sum_{n = 1}^{N_T}|h_m|^2}}\Bigr |^2 = \frac{\epsilon _s}{\sigma _n^2}\sum\limits_{n = 1}^{N_T}|h_n|^2 $}
		\item[$\Rightarrow$] same SNR as for maximum ration combining (MRC)
		\item[$\Rightarrow$] MRT with $N_T$ transmit antennas achieves the same performance as MRC with $N_T$ receive antennas
		\item[$\Rightarrow$] MRT/MRC can be extended to $ N_T\times N_R $ MIMO systems
		\begin{itemize}
			\item[$\rightarrow$] has the same performance as MRC with $N_T\cdot N_R$ receive antennas and one transmit antenna
		\end{itemize}
	\end{itemize}
\subsubsection*{Equal Gain Transmission (EGT)}
\begin{itemize}
	\item we employ gains: $w_n = \frac{1}{\sqrt{N_T}}\cdot \frac{h_n}{|h_m|} \rightarrow |w_n| = \frac{1}{\sqrt{N_T}} $
	\item SNR:
	\begin{align*}
		\gamma _t &= \frac{E_s}{\sigma _n^2}\left|\sum_{n = 1}^{N_T} w_n^*h_n \right |^2\\
		&= \frac{E_s}{\sigma _n^2}\left|\sum_{n = 1}^{N_T}\frac{1}{\sqrt{N_T}\cdot \frac{|h_n|^2}{|h_n|}} \right|^2 = \frac{1}{N_T}\cdot \frac{\mathcal{E}_s}{\sigma _n^2} \left|\sum_{n = 1}^{N_T}|h_n| \right|^2\\
		\gamma _n &= \frac{E_s}{\sigma _n^2}|h_n|^2\\
		&\text{same SNR as for EGC} \rightarrow \gamma _t = \frac{1}{N_T} \left| \sum_{n = 1}{N_T}\sqrt{\gamma _n} \right|^2
	\end{align*}
	\item[$\rightarrow$] EGC with $ N_T$ transmit antennas achieves the same performance as EGC with $ N_T$ receive antennas
\end{itemize}
\subsubsection*{Transmit Antennas Selection}
\begin{itemize}
	\item select antenna with maximum channel gain for transmission:
		\begin{align*} 
			w_n = 
			\begin{cases}
\frac{h_n}{|h_n|},  & \text{if } n = \hat{n}\\
0, & \text{otherwise}
\end{cases} \text{where } \hat{n} = \underset{n}{\mathrm{argmax}}|h_n|
		\end{align*}
	\item antenna selection with $ N_T$ transmit antennas achieves the same performance as \textit{Selection Combining} with $ N_T$ receive antennas
\end{itemize}
\subsection{No CSI at Transmitter - Space-Time-Coding}
\begin{itemize}
	\item $h_n, n\in\{1,\dots ,N_T\}$, is only known at the receiver
	\item ``Space-time-coding'' has to be employed to realize diversity gain
	\item $T\times N_T$ matrics $\mathbf{X}$ are transmitted in $T$ symbol intervals over $N_T$ antennas
	\item $\mathbf{X}$ is drawn from a matrix alphabet $\mathcal{X}$
	\item Example:
	\begin{align*}
		\mathbf{X}=\begin{pmatrix} x_{1,1} & x_{1,2} & \cdots & x_{1,N_T} \\
					   x_{2,1} & x_{2,2} & \cdots & x_{2,N_T} \\
					   \vdots  & \vdots  & \ddots & \vdots    \\
				 	   x_{T,1} & x_{T,2} & \cdots & x_{T,N_T}
			\end{pmatrix}
	\end{align*}
	\item We distinguish:
		\begin{itemize}
			\item Space-time-block-codes (STBCs)\\
			$\rightarrow$ $\mathbf{X}$ is obtained by mapping $K$ scalar symbols $s_k,\; k=1, \dots , K$ from a scalar alphabet $\mathcal{A}$ to matrix $\mathbf{X}$
			\item Space-time-trellis-codes (STTCs)\\
			$\rightarrow$ $\mathbf{X}$ is obtained from scalar symbols $s_k$ through a trellis encoding process.\\
			{\small[see: Tarokh, Seshadri, Calderbank: Space-time-codes for high datarate wireless communication: Performance criterions and coder construction; IEEE Trans. Inf. Theory 1998]}
			\item here: We concentrate on space-time-block-codes (STBCs), but many results can be easily extended to space-time-trellis-codes
		\end{itemize}
	\item STBCs:
		\begin{itemize}
			\item  $K$ $M$-ary scalar symbols (e.g. $M$-PSK symbols) are mapped to STBC matrices $\mathbf{X}$\\ 
			$\mathbf{S}=[s_1,\dots ,s_K] \rightarrow \mathbf{X}$\\
			$s_k\in \mathcal{A} \rightarrow x\in\mathcal{X}$ with $|\mathcal{X}|=M^K$
			\item Example: ``Alamouti''-Code\\
			\begin{align*}
				\mathbf{X}=\frac{1}{\sqrt{2}}
				\begin{pmatrix}
					s_1 & s_2 \\
					-s_2^* & s_1^*
				\end{pmatrix}
			\end{align*}
			{\small[Alamouti: A simple transmit diversity technique for wireless communication, IEEE JSAC 1998]}
		\end{itemize}
\end{itemize}
\subsubsection*{Optimal Detection}
\begin{itemize}
	\item Signal model:
	\begin{align*}
	\begin{pmatrix} y_1 \\ \vdots \\ y_T \end{pmatrix}&=\mathbf{X}\begin{pmatrix} h_1 \\ \vdots \\ h_{N_T} \end{pmatrix} + \begin{pmatrix} n_1 \\ \vdots \\ n_T \end{pmatrix}\\
	\mathbf{y}&=\mathbf{X}\cdot\mathbf{h}+\mathbf{n}
	\end{align*}
	\item Optimal detection - ML-detection
	\begin{itemize}
		\item $\mathbf{h}$ is known at receiver
		\item $\mathbf{n}$ is AWGN with $\mathcal{E}\{\mathbf{n}\cdot\mathbf{n^H}\}=\sigma_{\mathbf{n}}^2\cdots \mathbf{I}_{T\times T}$
		\item $p(\mathbf{y}|\mathbf{x})$
		\begin{align*}
		&=\frac{1}{\pi^T|\sigma_n^2\mathbf{I}_{T\times T}|}\mathrm{exp}\left(-(\mathbf{y - xh})^H(\sigma_n^2\mathbf{I}_{T\times T})^{-1}(\mathbf{y-xh})\right)\\
		&=\frac{1}{\pi^T\sigma_n^{2T}}\mathrm{exp}\left(-\frac{1}{\sigma_n^2}(\mathbf{y-xh})^H(\mathbf{y-xh})\right)=\frac{1}{\pi^T\sigma_n^{2T}}\mathrm{exp}\left(||\mathbf{y-xh}||^2\right)
		\end{align*}
		$\rightarrow$ the optimal estimate $\hat{\mathbf{X}}$ or equivalently the optimal estimate $\hat{\mathbf{s}}$ can be obtained as
		\begin{align*}
			\hat{\mathbf{s}}=\underset{\mathbf{s}\in\mathcal{A}^K}{\mathrm{argmax}}\;p(\mathbf{y|x})=\underset{\mathbf{s}\in\mathcal{A}^K}{\mathrm{argmin}}||\mathbf{y-hx}||^2
		\end{align*}
		\item Disadvantage: In general, metric $||\mathbf{y-hx}||^2$ has to be calculated $M^K$ times\\
		$\rightarrow$ complexity increases exponentially with $K$
	\end{itemize}
\end{itemize}
\subsubsection*{Types of STBCs}
\begin{itemize}
	\item Orthogonal STBCs (OSTBCs)
	\begin{itemize}
		\item OSTBCs are a special class of STBCs which allow independent detection of each $s_k \rightarrow$ only $K\cdot M$ metrics have to be evaluated
		\item Rate STBCs: $R_{STBC} = \frac{K}{T}$
		\item Examples:
		\begin{itemize}
			\item Alamouti Code  $(K = 2, T = 2) \rightarrow R_{STBC} = 1$
			\begin{align*}
				\textbf{X} &= \frac{1}{\sqrt{2}}\underset{\longleftrightarrow N_T}{\begin{pmatrix} s_1 & s_2 \\ -s_2^* & s_1^*	\end{pmatrix}}\updownarrow T\\
				\rightarrow &\text{ only ``full rate ´´ OSTBC for complex } s_k
			\end{align*}
			\item $N_T = 3, K = 3, T = 4$
			\begin{align*}
				\textbf{X} = \frac{1}{\sqrt{3}}\begin{pmatrix*}[r]	s_1 & s_2 & s_3 \\ -s_2^*  & s_1^* & 0 \\ s_3^* & 0 & -s_3^*\\0 & -s_3^* & s_2^*\end{pmatrix*} \rightarrow R_{STBC} = \frac{K}{T} = \frac{3}{4}
			\end{align*}
		\end{itemize}
		\item Orthogonality: $\textbf{X}^H\textbf{X} = {const}\cdot \textbf{I}_{N_T\times N_T}$
		\item Independent detection of $s_1$ \& $s_2$ for Alamouti Code
		\begin{align*}
				\begin{pmatrix*}[r]y_1 \\y_2 
			\end{pmatrix*} &= \frac{1}{\sqrt{2}}
			\begin{pmatrix*}[r]	s_1 & s_2 \\-s_2^* & s_1^*
			\end{pmatrix*}
			\begin{pmatrix*}[r]h_1\\h_2
			\end{pmatrix*} + 
			\begin{pmatrix*}[r]n_1\\n_2
			\end{pmatrix*}\\
			\rightarrow 
			\underbrace{
			\begin{pmatrix*}[r]y_1\\y_2
			\end{pmatrix*}}_{\tilde y} &= \frac{1}{\sqrt{2}}
			\underbrace{
			\begin{pmatrix*}[r]h_1 & h_2\\h_2^* & -h_1^*
			\end{pmatrix*}}_{\tilde F}
			\underbrace{
			\begin{pmatrix*}[r]s_1\\s_2
			\end{pmatrix*}}_{s} + 
			\underbrace{
			\begin{pmatrix*}[r]n_1\\n_2^*
			\end{pmatrix*}}_{\tilde n}
		\end{align*}
		$\Bigl ( $ Anmerkung: \underline{nur } $\begin{pmatrix}s_1 \\s_2 \end{pmatrix} $ gew\"unscht, nicht: $s_1^*, s_2^* \Bigr ) $
		\begin{align*}
			\textbf{F}^H\textbf{F} = \frac{1}{2}\begin{pmatrix}h_1^* & h_2\\h_2^* & -h_1\end{pmatrix}\begin{pmatrix}h_1 & h_2\\h_2^* & -h_1^* \end{pmatrix} = \frac{1}{2}\begin{pmatrix} |h_1|^2 + |h_2|^2 & 0\\0 & |h_1|^2 + |h_2|^2\end{pmatrix}		 								
		\end{align*}
		\begin{itemize}
			\item[$\rightarrow$] $\frac{\sqrt{2}}{\sqrt{|h_1|^2 + |h_2|^2}}\cdot \textbf{F} $ is unitary matrix 
			\item[$\rightarrow$] $\frac{2}{|h_1|^2 + |h_2|^2}\cdot \textbf{F}^H\cdot \tilde{\textbf{y}} = \textbf{s} + \frac{2}{|h_1|^2 + |h_2|^2}\cdot \textbf{F}^H\cdot\tilde{\textbf{n}}$ \\  $\bigl ( \frac{2}{|h_1|^2 + |h_2|^2}\cdot \textbf{F}^H\cdot\tilde{\textbf{n}}$ is AWGN vector with covariance matrix $\frac{2\sigma_n^2}{|h_1|^2 + |h_2|^2}\cdot \textbf{I}_{T\times T} \bigr)$
			\item[$\rightarrow$] ML decision: $\hat{\textbf{s}} = \underset{\textbf{s}}{\text{argmin}}\bigl | \bigl | \frac{2}{|h_1|^2 + |h_2|^2}\cdot \textbf{F}^H\cdot \tilde{\textbf{y}} - \textbf{s}\bigr |\bigr |^2 $
			\item[$\rightarrow$] independent ML decoding 
				\begin{align*}
					\hat{s}_1 &= \underset{s_1}{\text{argmin}} \Bigl |s_1 - \frac{h_1^*y_1 + h_2y_2^*}{\frac{1}{\sqrt{2}}(|h_1|^2 + |h_2|^2)}\Bigr |\\ \hat{s}_2 & = \underset{s_2}{\text{argmin}}\Bigl |s_2 - \frac{h_1^*y_1 - h_2y_2^*}{\frac{1}{\sqrt{2}}(|h_1|^2 + |h_2|^2)}\Bigr|
				\end{align*}
		\end{itemize}
		\item independent decoding property can be proved for all OSTBCs
		\item low complexity is at the expense of a rate-loss compared to other STBCs for $N_T > 2$
		\begin{itemize}
			\item[$\rightarrow$] Frequenzhopping
			\item[$\rightarrow$] keine Kanalinformation aus vorher empfangenen Symbolen m\"oglich $\Rightarrow$ Kanal \"andert sich st\"andig: nur Entscheidung, ob Rauschen oder Signal $+$ Rauschen	
		\end{itemize}
		\end{itemize}
		\item{Performance Analysis of Alamouti Code}
		\begin{itemize}
		\item Decision-variables after combining
		\begin{align*}
			r_1 &= \sqrt{2}\frac{h_1^*y_1 + h_2y_2^*}{|h_1|^2 + |h_2|^2}\\
			r_2 &= \sqrt{2}\frac{h_1^*y_1 - h_2y_2^*}{|h_1|^2 + |h_2|^2}
\end{align*} 
because of symmetry it suffices to consider $r_1$
		\begin{align*}
			r_1 &= \sqrt{2}\frac{h_1^*\bigl(\frac{1}{\sqrt{2}}s_1h_1 + \frac{1}{\sqrt{2}}h_2s_2 + n_1 \bigr) + h_2\bigl(-\frac{1}{\sqrt{2}}h_2s_1^* + \frac{1}{\sqrt{2}}h_1s_2^* + n_2\bigr)^*}{|h_1|^2 + |h_2|^2}\\ 
			&= \sqrt{2}\frac{\frac{1}{\sqrt2} \bigl(|h_1|^2 + |h_2|^2\bigr) s_1 + h_1^*n_1 + h_2n_2^*} {|h_1|^2 + |h_2|^2}\\
			&= 1\cdot s_1 + n_{eq}
		\end{align*}
		where 
		\begin{align*}
			n_{eq} &= \sqrt{2}\;\frac{h_1^*n_1 + h_2n_2^*}{|h_1|^2 + |h_2|^2}\\
			\text{SNR} \rightarrow \gamma _t  &= \frac{E_s\cdot 1^2}{\sigma _{eq}^2}\quad \text{with}\quad \mathcal{E}\bigl\{ |s_1|^2\bigr\} = \mathcal{E}_s\\ 	
			\sigma _{eq}^2 &= 2\frac{|h_1|^2\sigma _n^2 + |h_2|^2\sigma _{eq}}{\bigl(|h_1|^2 + |h_2|^2\bigr)^2} = \frac{2\sigma _n^2}{|h_1|^2 + |h_2|^2}
		\end{align*}
		\item[$\rightarrow$] $\gamma _t = \frac{1}{2}\frac{E_s}{\sigma _n}\bigl ( |h_1|^2 + |h_2|^2\bigr)$
		\item[$\rightarrow$] $\text{SNR}_{\text{Alamouti}} = \frac{1}{2}\text{SNR}_{\text{MRC}} = \frac{1}{2}\text{SNR}_{\text{MRT}}$
		\item[$\rightarrow$] Alamouti code has diversity gain $G_d = 2$
		\item[$\rightarrow$] Transmission with Alamouti STBC requires 3dB higher SNR to achieve same performance as MRT $\rightarrow$  3dB loss in coding gain $G_c$
		\item[$\rightarrow$] Lack of CSI knowledge at transmitter ``costs'' 3dB in power efficiency
		\item[$\rightarrow$] General: 
		\begin{itemize}
			\item[$\cdot$] OSTBCs achieve a diversity gain of $G_d = N_T$ if only one receive antenna is available
			\item[$\cdot$] if $ N_R $ receive antennas are available, MRC can be used at the receiver to yield a diversity gain of $\underline{G_d = N_TN_R}$
		\end{itemize}
	\end{itemize}
\item Other STBCs:
	\begin{itemize}
		\item Quasi orthogonal STBCs
		\begin{itemize}
			\item higher rate than OSTBCs
			\item only subset of symbols have to be decoded jointly
			\item Example: $K = N_T = T = 4$
			\begin{align*}
				\textbf{X} = \frac{1}{2}
				\begin{pmatrix*}[r]
					s_1 & s_2 & s_3 & s_4\\
					-s_2^* & s_1^* & -s_4^* & s_3^*\\
					-s_3^* & -s_4^* & s_1^* & s_2^*\\
					s_4 & -s_3 & -s_2 & s_1
				\end{pmatrix*}
			\end{align*}
			\item Anmerkung 1:  $\textbf{X} $ ist \"ahnlich zu Alamouti Code
			\item Anmerkung 2: $\textbf{X}^H\textbf{X}$: viele Nicht-diagonal Elemente sind Null; die, die ungleich Null sind, zeigen, welche Symbole gemeinsam entschl\"usselt werden m\"ussen 		
		\end{itemize}
		\item Golden Code for $ N_T = N_R = 2$: achieves a rate of $R_{STBC} = 2 $ and full diversity of $ G_d = N_T, N_R = 4$
		\item Differential STBCs: $\textbf{X}_k = \textbf{X}_{k-1}\cdot \textbf{D}_k $. $\textbf{X}_k $ is transmitted, $\textbf{D}_k $ is transmitted 
		\item Linear dispersion codes: designed to achieve high mutual information
		\item noncoherent STBCs (On-Off-Keying)
	\end{itemize}
\end{itemize}
\subsubsection*{Space Time Code Design}
Given: 
\begin{itemize}
	\item Code  $\mathscr{X} = \bigl\{\textbf{X}_1,\dots ,\textbf{X}_{|\mathscr{X}|}\bigr\}$
	\item Channel: IID Rayleigh-fading: 
	\begin{itemize}
		\item $h_n \sim \text{C}\mathcal{N}(0,1);\quad n \in \{1, 2, \dots , N_T \} $
		\item AWGN $ n \sim \text{C}\mathcal{N}(0,\sigma _n^2) $
	\end{itemize}
\end{itemize}
Problem: How should we design codebook $\mathscr{X}$?
\begin{itemize}
	\item Need to derive error rate for general codebooks $\mathscr{X}$!
	\begin{itemize}
		\item Codeword error rate\\
		\begin{align*}
			P_e=\frac{1}{|\mathscr{X}|}\sum\limits_{i=1}^{|\mathscr{X}|}\mathrm{Pr}\{\mathbf{x}_i\neq\hat{\mathbf{x}}_i\}
		\end{align*}
		where $\hat{\mathbf{x}}_i$ is the detected codeword and we assume that all codewords are equally likely
	\end{itemize}
\underline{Problem:} $\mathrm{Pr}\{\mathbf{x}_i\neq\hat{\mathbf{x}}_i\}$ is not tractable in general
	\item  Use union bound to upper bound $\mathrm{Pr}\{\mathbf{x}_i\neq\hat{\mathbf{x}}_i\}$ as upper sum over \underline{pairwise error probabilities}(PEP)
	$\mathrm{Pr}\{\mathbf{x}_i\rightarrow\mathbf{x}_j\}$ where it is assumed that $\mathbf{x}_i$ was transmitted and $\mathbf{x}_i$ and $\mathbf{x}_j$ are the
	only codewords in the codebook
	\begin{align*}
	\boxed{P_e\leq \frac{1}{|\mathscr{X}|}\sum\limits_{i=1}^{|\mathscr{X}|}\sum\limits_{j=1}^{|\mathscr{X}|}\mathrm{Pr}\{\mathbf{x}_i\rightarrow\mathbf{x}_j\} \text{ where } j \neq i}
	\end{align*}
\underline{Calculation of PEPs}\\
Recall: $\hat{\mathbf{x}}=\underset{\mathbf{x}\in\mathscr{X}}{\mathrm{argmin}}||\mathbf{y-xh}||^2$\\
Now, $\mathbf{x}_i$ and $\mathbf{x}_j$ are the only alternatives and an error is made if $||\mathbf{y-x_{\mathnormal{i}}h}||^2>||\mathbf{y-x_{\mathnormal{j}}h}||^2$ since $\mathbf{x}_i$ was sent but $\mathbf{x}_j$ was detected
	\begin{align*}
	\rightarrow	||\mathbf{x_{\mathnormal{i}}h+n-x_{\mathnormal{i}}h}||^2 &>||\mathbf{x_{\mathnormal{i}}h+n-x_{\mathnormal{j}}h}||^2\\
			||\mathbf{n}||&>||\mathbf{(x_{\mathnormal{i}}-x_{\mathnormal{j}})h+n}||^2\\
	\rightarrow	||\mathbf{n}||&>\underbrace{\mathbf{h^{\mathnormal{H}}(x_{\mathnormal{i}}-x_{\mathnormal{j}})^{\mathnormal{H}}(x_{\mathnormal{i}}-x_{\mathnormal{j}})h}}_{\Delta}
			+\mathbf{h^{\mathnormal{H}}(x_{\mathnormal{i}}-x_{\mathnormal{j}})n+n^{\mathnormal{H}}(x_{\mathnormal{i}}-x_{\mathnormal{j}})h+||n||^{\mathnormal{2}}}
	\end{align*}
	\begin{align*}
		\rightarrow \underbrace{\mathbf{-h^{\mathnormal{H}}(x_{\mathnormal{i}}-x_{\mathnormal{j}})^{\mathnormal{H}}n-n^{\mathnormal{H}}(x_{\mathnormal{i}}-x_{\mathnormal{j}})h}}_{z}>\Delta
	\end{align*}
for given $\mathbf{h}$, $z$ is a gaussian random variable
\begin{align*}
	\sigma_z^2&=\mathcal{E}\{|z|^2\}=\mathcal{E}\{2\mathbf{h}^H(\mathbf{x}_i-\mathbf{x}_j)\overbrace{\mathbf{nn}^H}^{\sigma_n^2\mathbf{I}}(\mathbf{x}_i-\mathbf{x}_j)\mathbf{h}
	+2\mathbf{h}^H(\mathbf{x}_i-\mathbf{x}_j)^H\overbrace{\mathbf{nn}^T}^{=0}(\mathbf{x}_i-\mathbf{x}_j)^*\mathbf{h}^*\}\\
		&=2\sigma_n^2\Delta+0
\end{align*}
\begin{align*}
	\mathrm{Pr}\{\mathbf{x}_i\rightarrow\mathbf{x}_j\}&=\int\limits_{\Delta}^{\infty}\frac{1}{\sqrt{2\pi}\sigma_z}\mathrm{exp}\left(-\frac{z^2}{2\sigma_z^2}\right)\mathrm{d}z, \; t=\frac{z}{\sigma_z}\\
	&=\frac{1}{\sqrt{2\pi}}\int\limits_{\frac{\Delta}{\sigma_z}}^{\infty}e^{-\frac{t^2}{2}}\mathrm{d}t=Q\left(\frac{\Delta}{\sigma_z}\right)=Q\left(\frac{\Delta}{\sqrt{2\sigma_n^2\Delta}}\right)\\
	&=Q\left(\sqrt{\frac{\Delta}{2\sigma_n^2}}\right)
\end{align*}
	\item $\mathrm{Pr}\{\mathbf{x}_i\rightarrow\mathbf{x}_j\}=\mathcal{E}\left\{Q\left(\sqrt{\frac{\Delta}{2\sigma_n^2}}\right)\right\}$
	\begin{itemize}
	\item to avoid cumbersome Q-function we use Chernoff bound:
	\begin{align*}	
		\boxed{Q(x)\leq\frac{1}{2}e^{-\frac{x^2}{2}}}\\
	\end{align*}
	\begin{align*}
		\mathrm{Pr}\{\mathbf{x}_i\rightarrow\mathbf{x}_j\}\leq \frac{1}{2}\mathcal{E}_h\left\{\mathrm{exp}\left(-\frac{\mathbf{h}^H\mathbf{Qh}}{4\sigma_n^2}\right)\right\}\\
		\text{where } \mathbf{Q}=(\mathbf{x}_i-\mathbf{x}_j)^H(\mathbf{x}_i-\mathbf{x}_j)
	\end{align*}
	\end{itemize}
	\item Eigendecomposition: $\mathbf{Q=U}^H\mathbf{\Lambda U}$ with $\mathbf{\Lambda} = \mathrm{diag}\{\lambda_1,\dots,\lambda_r, 0,\dots,0\}\qquad r=\mathrm{rank}\{\mathbf{Q}\}$\\

	\item Elements $\mathbf{h}$ are i.i.d. Gaussian
	\begin{itemize}	
		\item $\mathbf{\underline{\beta}=Uh}$ has also i.i.d. Gaussian random variables as elements since $\mathbf{U}$ is unitary matrix
		\item $\mathbf{h}^H\mathbf{Qh}=\underbrace{\mathbf{h}^H\mathbf{U}^H}_{\underline{\beta}^*}\mathbf{\Lambda}\underbrace{\mathbf{Uh}}_{\underline{\beta}}=\sum\limits_{i=1}^r\lambda_i|\beta_i|^2$ 
		with $\underline{\beta}=[\beta_1,\dots,\beta_{N_T}]$
	\end{itemize}
	\begin{align*}
	\mathrm{Pr}\{\mathbf{x}_i\rightarrow\mathbf{x}_j\}&=\frac{1}{2}\mathcal{E}_{\underline{\beta}}\left\{\mathrm{exp}\left(-\frac{\sum\limits_{i=1}^r\lambda_i|\beta_i|^2}{4\sigma_n^2}\right)\right\}\\
	&=\frac{1}{2}\mathcal{E}_{\underline{\beta}}\left\{\prod\limits_{i=1}^r e^{-\frac{\lambda_i}{4\sigma_n^2}|\beta_i|^2}\right\}\\
	&=\frac{1}{2}\prod\limits_{i=1}^r\mathcal{E}_{\beta_i}\left\{e^{-\frac{\lambda_i}{4\sigma_n^2}|\beta_i|^2}\right\}\\
	&=\frac{1}{2}\prod\limits_{i=1}^r \mathcal{E}_{|\beta_i|^2}\left\{e^{-\frac{\lambda_i}{4\sigma_n^2}|\beta_i|^2}\right\}\mathrel{\widehat{=}}\text{MGF of exponentially distributed variable } \alpha_i=|\beta_i|^2\\
	\end{align*}
	$\rightarrow P_{\alpha_i}(x)=e^{-x},\; x\geq 0$
	\begin{align*}
	\rightarrow \mathrm{Pr}\{\mathbf{x}_i\rightarrow \mathbf{x}_j\}&\leq \frac{1}{2}\prod\limits^r_{i=1}\frac{1}{1+\frac{\lambda_i}{4\sigma_n^2}}\\
	&\leq\prod\limits^r_{i=1}\frac{1}{\frac{\lambda_i}{4\sigma_n^2}}=2^{2r-1}\frac{1}{\prod\limits^r_{i=1}\lambda_i}\left(\underbrace{\frac{1}{\sigma_n^2}}_{\mathrel{\widehat{=}}SNR}\right)^{-r}
	\end{align*}
	\item upper bound on $P_e$: 
	\begin{align*}
		\lambda_n(i,j) &= n\text{th eigenvalue of }(\mathbf{x}_i-\mathbf{x}_j)^H(\mathbf{x}_i-\mathbf{x}_j)\\
		r(i,j) &= \text{ rank of }(\mathbf{x}_i-\mathbf{x}_j)^H(\mathbf{x}_i-\mathbf{x}_j)
	\end{align*}
	\begin{align*}
	\rightarrow P_e \leq \frac{1}{\mathscr{|X|}} \sum\limits_{i=1}^{\mathscr{|X|}}\sum\limits_{j=1}^{\mathscr{|X|}}2^{2r(i,j)-1}\frac{1}{\prod\limits_{n=1}^{r(i,j)}\lambda_n(i,j)}\left(\frac{1}{\sigma_n^2}\right)^{-r(i,j)}
	\end{align*}
	\item generally loose bound but offers significant insight for code design
\end{itemize}
\vspace{1.6cm}
{\large\underline{Two criteria:}}\\
	\begin{description}
		\item[\underline{Rank criterion:}]The diversity gain of a ST code is given by $G_d=\underset{i,j}{\mathrm{min}}(r(i,j))
		=\underset{i,j}{\mathrm{min}}\;\mathrm{rank}\left((\mathbf{x}_i-\mathbf{x}_j)^H(\mathbf{x}_i-\mathbf{x}_j)\right)$
		$\rightarrow$ Design code such that minimum rank of all possible matrices $(\mathbf{x}_i-\mathbf{x}_j)^H(\mathbf{x}_i-\mathbf{x}_j)$ is maximized
		\begin{align*}
			T \updownarrow  \overset{\overset{N_T}{\longleftrightarrow}}{\mathbf{X}_i} \Rightarrow r(i,j)=N_T\qquad \forall i\neq j
		\end{align*}
		\item[\underline{Determinant criterion:}]To maximize the coding gain among all codes with $r(i,j)=N_T$, we need to maximize 
		$\mathrm{max}\;\underset{i,j}{\mathrm{min}}\prod\limits_{n=1}^{N_T}\lambda_n(i,j)=\mathrm{max}\;\underset{i,j}{\mathrm{min}}\left|(\mathbf{x}_i-\mathbf{x}_j)^H(\mathbf{x}_i-\mathbf{x}_j)\right| \qquad \forall i \neq j$
	\end{description}
\begin{itemize}
	\item Rank and determinant criterion can be used for the search for good space-time block codes and space-time trellis codes. These two criteria were first derived by Tarokh, et. al. 1998.
	\item diversity increases to $N_TN_R$ if $N_K$ receive antennas are available
	\item Example: see B\"aro, Bauch, Hansmann: Improved codes for space-time trellis coded modulation. IEEE Comm. Letters, 2000.
\end{itemize}
\subsection*{Partial or Imperfect CSI at the Transmitter}
\begin{itemize}
	\item In practice, the CSI cannot be perfect. Channel estimation, quantization and noisy feedback channels introduce errors.
	\item If the system is optimized for perfect CSI (\textit{e.g.} using MRT or EGT), the performance for imperfect CSI may be worse than for a system designed for no CSI(\textit{e.g.} space-time coding)
	\item In this case, it is advantageous to use a hybrid approach and combine beamforming and space-time coding.
\end{itemize}
\begin{figure}[h]
	\centering
	\input{STBEAM.pstex_t}
\end{figure}
\begin{itemize}
	\item $\mathbf{W}$ is the beamforming matrix which depends on the reliability of the CSI
	\item CSI is modeled as
	\begin{align*}
	\hat{h}_i=\rho h_i+\sqrt{1-\rho^2}e_i
	\end{align*}
	where:
		\begin{itemize}
			\item $\hat{h}_i$ is the CSI estimate
			\item $\rho$ is the correlation between $\hat{h}_i$ and $h_i$
			\item $e_i$ is the CSI error modeled as AWGN
		\end{itemize}
	extreme cases:
		\begin{itemize}
			\item $\rho = 0$ : $\hat{h}_i$ independent of $h_i$ $\rightarrow$ no CSI ($\mathbf{W}=\mathbf{I}$)
			\item $\rho = 1$ : $\hat{h}_i=h_i$ $\rightarrow$ perfect CSI ($\mathbf{W}$ performs MRT)
		\end{itemize}
	\item $\mathbf{W}$ can be optimized under the assumptions for given $\rho$ and $\hat{h}_i$\\
	$\rightarrow$ see for details: J\"ongren, Skorglund and Ottersten: "Combining Beamforming and Orthogonal Space-time Block Coding", IEEE on IT, 2002.
\end{itemize}
\section{MIMO Systems without CSI at the transmitter}
\begin{itemize}
	\item We consider $N_T\times N_R$ MIMO system and assume that the channel matrix $\mathbf{H}$ is not known at the transmitter\\
	$\rightarrow$ no CSI at the transmitter (CSIT)
	\item signal model:
	\begin{align*}
		N_R \updownarrow\mathbf{y}=N_R \updownarrow \overset{\overset{N_T}{\longleftrightarrow}}{\mathbf{H}}\mathbf{x}\updownarrow N_T+\mathbf{n} \updownarrow N_R
	\end{align*}
	\begin{figure}[h]
		\centering
		\input{SIGMOD.pstex_t}
	\end{figure}
	\item $x_n$ are $M$-ary i.i.d. scalar symbols taken \textit{e.g} from an $M$-PSK or $M$-QAM symbol alphabet $\mathscr{A}$
	\item This scheme is often called ``spatial multiplexing''
	\item We transmit $N_T$ symbols per symbol interval\\
	$\rightarrow$ rate $R=\log_2(M)\cdot N_T$ for uncoded transmission
	\item Problem: How to detect $\mathbf{x}$ at the receiver considering
		\begin{itemize}
			\item performance
			\item complexity
		\end{itemize}
\end{itemize}
\subsection*{Optimum Detection}
\begin{itemize}
	\item Elements of $\mathbf{n}$ are gaussian random variables with variance $\sigma_n^2$
	\item $\mathbf{H}$ is known at the receiver
	\begin{align*}
		p(\mathbf{y}|\mathbf{x})&=\frac{1}{\pi^{N_R}\sigma_n^2\mathbf{I}_{N_R \times N_R}} \exp \left(-(\mathbf{y}-\mathbf{Hx})^H(\sigma_n^2\mathbf{I}_{N_R \times N_R})^{-1}(\mathbf{y}-\mathbf{Hx})\right)\\
		&=\frac{1}{\pi^{N_R}\sigma_n^{2N_R}}\exp\left(-\frac{1}{\sigma_n^2}||\mathbf{y}-\mathbf{xH}||^2\right)
	\end{align*}
	\item ML-Detection
	\begin{align*}
		\hat{x}=\underset{\mathbf{x}\in \mathscr{A}^{N_T}}{\mathrm{argmin}}||\mathbf{y}-\mathbf{xH}||^2=\underset{\mathbf{x}\in \mathscr{A}^{N_T}}{\mathrm{argmax}}\quad p(\mathbf{y}|\mathbf{x})
	\end{align*}
	\begin{itemize}
		\item[$\rightarrow$] $M^{N_T}$ metric calculations $\rightarrow$ complexity is exponential in $N_T$!!
		\item[$\rightarrow$] in general too complex in practice
	\end{itemize}
	\item Performance 
	\begin{itemize}
		\item consider worst case pairwise error probability (PEP) to evaluate \underline{diversity gain}
		\item PEP $\rightarrow$ $x_i$ is transmitted but $x_j\neq x_i$ is detected\\
		this happens if $||\mathbf{y}-\mathbf{Hx}_i||^2 > ||\mathbf{y}-\mathbf{Hx}_j||^2$\\
		$\rightarrow\; ||\mathbf{n}||^2>||\mathbf{H}(\mathbf{x}_i-\mathbf{x}_j)+\mathbf{n}||^2$
		\item the ``worst case'' is if $\mathbf{x}_i$ \& $\mathbf{x}_j$ differ only in one element \textit{i.e.},
		\begin{align*}
			 \mathbf{x}_i-\mathbf{x}_j=(x_{ni}-x_{nj})= \begin{bmatrix*} 0 \\ 0 \\ 0 \\ \vdots \\  1 \\ \vdots \\ 0 \\ 0  \end{bmatrix*}\leftarrow \text{``1'' in position } n
		\end{align*}
		where $\mathbf{x}_i=[x_{1i},x_{2i},\dots,x_{N_Ti}]$
		\item $||\mathbf{n}||^2>||\underbrace{\mathbf{h}_n}_{\text{$n$th column of $\mathbf{H}$}}\underbrace{(x_{ni}-x_{nj})}_{\Delta x_n(i,j)}+\mathbf{n}||^2$
		\item $||\mathbf{n}||^2> \mathbf{h}_n^H\mathbf{n} \Delta x^*_n(i,j)+\mathbf{n}^H\mathbf{h}_n\Delta x_n(i,j)+||\mathbf{n}||^2+||\mathbf{h}_n||^2-|\Delta x_n(i,j)|^2$
		\begin{align*}
			||\mathbf{h}_n||^2|\Delta x_n(i,j)|^2<\underbrace{-\mathbf{h}_n^H\mathbf{n}\Delta x_n(i,j)-\mathbf{n}^H\mathbf{h}_n \Delta x_n(i,j)}_
			{\text{Gaussian random variable with variance $\sigma_{eq}^2=2\sigma_n^2|\Delta x_n(i,j)|^2||\mathbf{h}_n||^2$}}
		\end{align*}
		\item $\mathrm{Pr}\{\mathbf{x}_i\rightarrow \mathbf{x}_j\|\mathbf{H}\}=Q\left(\sqrt{\frac{||\mathbf{h}_n||^2|\Delta x_n(i,j)|^2}{2\sigma_n^2}}\right)$
		\item $\mathrm{Pr}\{\mathbf{x}_i\rightarrow \mathbf{x}_j\}=\mathcal{E}\left\{Q\left(\sqrt{\frac{||\mathbf{h}_n||^2|\Delta x_n(i,j)|^2}{2\sigma_n^2}}\right)\right\}$\\
		$\rightarrow$ use same approach as for space-time code design to get diversity order\\
		or : SNR is 
		\begin{align*}
			\gamma_t = \frac{||\mathbf{h}_n||^2|\Delta x_n(i,j)|^2}{2\sigma_n^2} = \frac{|\Delta x_n(i,j)|^2}{2\sigma_n^2}(|h_{1n}|^2+|h_{2n}^2+\dots+|h_{N_Rn}|^2)
		\end{align*}
		\item same form as SNR of MRC with $N_R$ receive antennas
		\item diversity gain of spatial multiplexing wit ML-decoding is
		\begin{align*}
			G_d=N_R
		\end{align*}
		\item diversity of $N_T$ transmit antennas is not exploited with spatial multiplexing
		\item to exploit this additional gain, coding across space is required (at the expense of rate)\\
			(Hier geh\"oren die detection performance kurven f\"ur BPSK hin)
	\end{itemize}
\end{itemize}
\subsection*{Linear Receivers}
\begin{itemize}
	\item How can we avoid the complexity associated wit the joint detection of the elements of $\mathbf{x}$?
	\item Idea: Employ linear filter (matrix) to seperate  the elements of $\mathbf{x}$
	\item Requires: $N_T \leq N_R$
	\item We form
	\begin{align*}
		\mathbf{r}=N_T\updownarrow &\overset{\overset{N_R}{\longleftrightarrow}}{\mathbf{F}}\mathbf{y}=[r_1,\dots,r_{N_T}]^T\\
	&\text{where $\mathbf{F}$ is the filter matrix and $\mathbf{y}$ is the received vector}
	\end{align*}
	such that $x_n$ can be obtained from
	\begin{align*}
		\hat{x}_n&=\underset{x_n \in \mathscr{A}}{\mathrm{argmin}} \; |r_i-x_n|^2
		&\text{where } \mathbf{F} \in \mathbb{C}^{N_T\times N_R}
	\end{align*}
	\item Two popular design criteria for $\mathbf{F}$
	\begin{itemize}
		\item Zero-forcing (ZF) criterion
		\item minimum mean squared error (MMSE) crtiterion
	\end{itemize}
\end{itemize}
\end{document}
